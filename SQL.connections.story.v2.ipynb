{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# De lo *difícil* a lo *fácil*: conectar y trabajar con bases de datos usando **sqlite3**, **pandas** y **SQLAlchemy**\n\nEste cuaderno sirve como **referencia** para que veas dos formas de trabajar con bases de datos y, después, cómo **generalizar** el patrón a otros motores:\n\n1. **Camino “manual” con `sqlite3`**: hacemos `DROP/CREATE/INSERT/SELECT` y gestionamos `cursor` y `commit`. Así se entiende qué pasa *por debajo*.\n2. **Camino “sencillo” con SQLAlchemy + pandas**: repetimos el flujo desde cero pero ahora **sin** manejar cursor ni DDL/INSERT a mano: `create_engine`, `to_sql`, `read_sql`.\n3. **Generalización a MySQL y PostgreSQL**: mismo código de lectura/escritura; **solo cambia la URL de conexión**.\n\nAl final, verás **beneficios** y **limitaciones** de este enfoque, más un mini **troubleshooting**.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Tabla de contenidos\n1. [Parte A — SQLite *sin* SQLAlchemy (camino manual)](#parte-a)\n2. [Parte B — SQLite *con* SQLAlchemy + pandas (camino sencillo)](#parte-b)\n3. [Parte C — Misma idea con MySQL](#parte-c)\n4. [Parte D — Misma idea con PostgreSQL](#parte-d)\n5. [Beneficios, limitaciones y notas útiles](#beneficios)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n<a id=\"parte-a\"></a>\n# Parte A — SQLite *sin* SQLAlchemy (camino manual)\n\n**Objetivo:** entender *qué hay que hacer a bajo nivel* cuando no usamos SQLAlchemy. Trabajaremos con `sqlite3` para crear una tabla, insertar datos y consultarlos.\n\n**Qué veremos:**\n- Conexión a un fichero `.db`\n- Uso de `cursor` y `execute(...)`\n- DDL/INSERT “a mano” (`DROP/CREATE/INSERT`)\n- `commit()` para confirmar cambios\n- `SELECT` y lectura con `fetchall()`\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import os\nimport sqlite3\nimport pandas as pd  # Solo para mostrar luego cómo se vería en DataFrame\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Conexión a un fichero SQLite (se crea si no existe)\ncon = sqlite3.connect(r'./bases.datos/sqlite_db_story.db')\ncon\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# (1) Limpiar si existe: DROP TABLE\ndrop_query = \"DROP TABLE IF EXISTS projects;\"\ncursor = con.cursor()\ncursor.execute(drop_query)\ncon.commit()  # Confirmamos cambios DDL\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# (2) Crear tabla: CREATE TABLE\ncreate_query = '''\nCREATE TABLE IF NOT EXISTS projects (\n    id INTEGER PRIMARY KEY,\n    name TEXT NOT NULL,\n    begin_date TEXT,\n    end_date TEXT\n);\n'''\ncursor = con.cursor()\ncursor.execute(create_query)\ncon.commit()\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# (3) Insertar datos: INSERT\ninsert_query = '''\nINSERT INTO projects (id, name, begin_date, end_date) VALUES\n(1, 'Juan',  '2024-01-01', '2024-06-30'),\n(2, 'Ana',   '2024-03-15', '2024-09-15'),\n(3, 'Lucía', '2024-05-01', NULL);\n'''\ncursor = con.cursor()\ncursor.execute(insert_query)\ncon.commit()  # ¡IMPORTANTE!\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# (4) Consultar: SELECT + fetchall()\nselect_query = \"SELECT id, name, begin_date, end_date FROM projects;\"\ncursor = con.cursor()\ncursor.execute(select_query)\nrows = cursor.fetchall()\nrows  # Lista de tuplas\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# (5) (Opcional) Verlo como DataFrame (misma conexión, sin SQLAlchemy)\ncols = ['id', 'name', 'begin_date', 'end_date']\npd.DataFrame(rows, columns=cols)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Conclusión de la Parte A**  \nTrabajar sin SQLAlchemy **funciona**, pero hay que ocuparse de:\n- crear/eliminar tablas,\n- preparar `INSERT`s,\n- acordarse del `commit()`,\n- y gestionar el `cursor`.\n\nAhora repetimos **desde cero** con **SQLAlchemy + pandas**, donde parte de todo esto se simplifica mucho.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n<a id=\"parte-b\"></a>\n# Parte B — SQLite *con* SQLAlchemy + pandas (camino sencillo)\n\n**Objetivo:** repetir el caso anterior pero:\n- Conexión con `create_engine('sqlite:///ruta.db')`\n- Crear/poblar la tabla **directamente** desde un `DataFrame` con `.to_sql(...)`\n- Leer con `pd.read_sql(...)`\n- Sin `cursor`, sin `commit` explícito, y sin escribir `CREATE/INSERT` a mano\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from sqlalchemy import create_engine\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Nueva base/tabla para partir de cero\nengine_sqlite = create_engine('sqlite:///./bases.datos/sqlite_db_story_sqlalchemy.db')\nengine_sqlite\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Creamos un DataFrame de ejemplo y lo escribimos a la BD\ndf_projects = pd.DataFrame({\n    'id': [1, 2, 3],\n    'name': ['Juan', 'Ana', 'Lucía'],\n    'begin_date': ['2024-01-01', '2024-03-15', '2024-05-01'],\n    'end_date': ['2024-06-30', '2024-09-15', None]\n})\n\n# .to_sql crea la tabla si no existe y hace los INSERTs por nosotros\ndf_projects.to_sql('projects', con=engine_sqlite, if_exists='replace', index=False)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Leemos con pandas\npd.read_sql(\"SELECT * FROM projects\", con=engine_sqlite)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Podemos añadir filas fácilmente\ndf_more = pd.DataFrame({\n    'id': [4],\n    'name': ['Marcos'],\n    'begin_date': ['2024-06-01'],\n    'end_date': [None]\n})\ndf_more.to_sql('projects', con=engine_sqlite, if_exists='append', index=False)\n\npd.read_sql(\"SELECT * FROM projects ORDER BY id\", con=engine_sqlite)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Comentarios rápidos (Parte B):**\n- `.to_sql(..., if_exists='replace')` **borra y recrea** la tabla (¡cuidado!).   Usa `'append'` para añadir filas.\n- **No** hemos escrito `CREATE/INSERT` ni gestionado `cursor` o `commit` a mano.\n- En tablas reales quizá quieras **tipos de datos más precisos** o **claves**;\n  `.to_sql` hace una inferencia básica. Para control avanzado puedes crear la tabla antes o usar tipos de SQLAlchemy, pero aquí **priorizamos sencillez**.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n<a id=\"parte-c\"></a>\n# Parte C — Misma idea con **MySQL**\n\n**Supuesto:** MySQL corre en Docker y escucha en `localhost:3306` (ajusta a tu entorno). Con **pandas + SQLAlchemy** el código de lectura/escritura es **igual**; solo cambia la **URL de conexión**.\n\n> Si tu driver no está instalado, podrías necesitar: `pip install sqlalchemy mysqlclient`\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from sqlalchemy import create_engine\nimport pandas as pd\n\nmysql_user = \"root\"\nmysql_password = \"rootpass\"\nmysql_host = \"localhost\"\nmysql_port = 3306\nmysql_db = \"test_db\"\n\nmysql_url = f\"mysql://{mysql_user}:{mysql_password}@{mysql_host}:{mysql_port}/{mysql_db}\"\nengine_mysql = create_engine(mysql_url)\nengine_mysql\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Escribimos un DataFrame en MySQL\ndf_mysql = pd.DataFrame({'a': [10, 20], 'b': ['hola', 'caracola']})\ndf_mysql.to_sql('demo_mysql', con=engine_mysql, if_exists='append', index=False)\n\n# Y leemos igual que en SQLite\npd.read_sql(\"SELECT * FROM demo_mysql\", con=engine_mysql)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n<a id=\"parte-d\"></a>\n# Parte D — Misma idea con **PostgreSQL**\n\n**Supuesto:** PostgreSQL corre en Docker y escucha en `localhost:5432`. Para el driver de PostgreSQL solemos usar `psycopg2`.\n\n> Si hace falta: `pip install sqlalchemy psycopg2-binary`\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from sqlalchemy import create_engine\nimport pandas as pd\n\npg_user = \"postgres\"\npg_password = \"postgres\"\npg_host = \"localhost\"\npg_port = 5432\npg_db = \"test_db\"\n\npg_url = f\"postgresql+psycopg2://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_db}\"\nengine_pg = create_engine(pg_url)\nengine_pg\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Misma operación: escribir y leer\ndf_pg = pd.DataFrame({'x': [1, 2, 3], 'y': ['A', 'B', 'C']})\ndf_pg.to_sql('demo_pg', con=engine_pg, if_exists='append', index=False)\n\npd.read_sql(\"SELECT * FROM demo_pg\", con=engine_pg)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n<a id=\"beneficios\"></a>\n# Beneficios, limitaciones y notas útiles\n\n## ¿Por qué este enfoque funciona tan bien?\n- **Portabilidad:** con `pandas + SQLAlchemy` el **patrón es idéntico** entre SQLite, MySQL y PostgreSQL;   cambia la **URL de conexión** y poco más.\n- **Simplicidad:** `to_sql`/`read_sql` cubren el 80% de casos típicos de clase/prototipado.\n- **Rapidez de desarrollo:** menos SQL manual, menos `cursor`, menos `commit` explícito.\n\n## ¿Qué limitaciones tiene?\n- **Tipos y claves:** `.to_sql` hace *inferencia básica*. Si necesitas claves primarias compuestas, índices,   tipos muy específicos, etc., tendrás que **crear la tabla** tú mismo/a (DDL) o usar tipos de SQLAlchemy.\n- **Control fino:** para transacciones complejas o SQL avanzado, escribir queries manuales sigue siendo útil.\n- **Rendimiento en volumen:** para cargas muy grandes conviene considerar `chunksize=...`, COPY (en Postgres),   o utilidades específicas del motor.\n\n## Consejos y resolución de problemas\n- **Drivers:** si MySQL o Postgres no conectan, revisa que tengas el driver instalado (`mysqlclient` / `psycopg2-binary`).  \n- **Docker:** comprueba que los contenedores están levantados y los puertos mapeados (`3306`, `5432`).  \n- **Credenciales/host:** asegúrate de usuario, contraseña, host/IP y DB correctos.  \n- **`if_exists`:** `'append'` añade filas; `'replace'` borra y recrea la tabla (¡ojo!).  \n- **Seguridad:** no dejes credenciales en claro en proyectos reales; usa `.env`/variables de entorno.\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundamentals_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}